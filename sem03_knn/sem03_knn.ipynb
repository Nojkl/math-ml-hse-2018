{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Машинное обучение\n",
    "\n",
    "## Факультет математики НИУ ВШЭ\n",
    "\n",
    "### 2018-2019 учебный год\n",
    "\n",
    "Лектор: Илья Щуров\n",
    "\n",
    "Семинаристы: Евгения Ческидова, Евгений Ковалев\n",
    "\n",
    "Ассистенты: Константин Ваниев, Софья Дымченко"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Семинар 3\n",
    "\n",
    "Сегодня мы узнаем\n",
    "\n",
    "* Что такое обучение с учителем, что такое непараметрические и параметрические алгоритмы ml\n",
    "* Как работает метод ближайших соседей, какие у него есть параметры и как они влияют\n",
    "* Что такое скользящий контроль и какой он бывает\n",
    "* Узнаем о разложении ошибки на смещение и разброс\n",
    "* Узнаем о влиянии размерности пространства признаков на эффективность алгоритма knn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Метод K ближайших соседей\n",
    "## K nearest neighbours"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Алгоритм KNN является надежным и универсальным классификатором, который часто используется в качестве бейзлайна для более сложных классификаторов, таких как искусственные нейронные сети (ANN). Несмотря на свою простоту, KNN может превзойти более мощные классификаторы и используется во множестве приложений, таких как экономическое прогнозирование, сжатие данных и генетика. Например, KNN использовалась в [исследовании](https://bmcbioinformatics.biomedcentral.com/articles/10.1186/1471-2105-7-S1-S11) по функциональной геномике в 2006 году, где гены определялись на основе их профилей экспрессии.\n",
    "\n",
    "# Что такое алгоритм KNN?\n",
    "\n",
    "Начнем с введения некоторых определений и обозначений.\n",
    "\n",
    "* Мы будем использовать $x$ для обозначения вектора признаков (или атрибутов) объекта.\n",
    "* Под $y$ мы будем подразумевать метку или класс, который мы пытаемся предсказать.\n",
    "\n",
    "**Обучение с учителем**\n",
    "\n",
    "KNN входит в число **supervised** алгоритмов или алгоритмов \"обучения с учителем\".\n",
    "Это означает, что нам предоставляется размеченный набор данных, для которого известны соответствия между наблюдениями $(x, y)$. Целью является на основе предоставляемой выборки найти связь между $x$ и $y$, чтобы восстановить функцию $h: X \\rightarrow Y$. Имея такую функцию мы можем предсказать $y$ по имеющемуся наблюдению $x$.\n",
    "\n",
    "**Классификатор KNN также является непараметрическим алгоритмом обучения**\n",
    "\n",
    "Непараметрический означает, что алгоритм не делает явных предположений о функциональной форме $h$, избегая опасностей ошибочного определения лежащего в основе распределения данных. Например, предположим, что наши данные сильно негауссовы, но выбранная нами модель обучения делает сильное предположение о гауссовой форме распределения. В этом случае такой алгоритм сделает крайне плохие прогнозы.\n",
    "\n",
    "Обучение KNN заключается в запоминании экземпляров обучающей выборки, которые впоследствии используются как «знание» для фазы прогнозирования. Конкретно это означает, что только когда запрос в нашу базу данных сделан (т.е. когда мы просим KNN предсказать метку с учетом ввода), алгоритм будет использовать экземпляры обучения, чтобы выдать ответ.\n",
    "\n",
    "**С какими сложностями можно столкнуться при обучении алгоритма KNN?**\n",
    "\n",
    "Нужно понимать, что фаза обучения, заключающаяся в запоминании объектов выборки не является дорогостоящей по времени.\n",
    "Однако этого нельзя сказать о фазе тестирования. Если база обучения достаточно большая, осуществление поиска по ней достаточно дорогостоящий процесс.\n",
    "\n",
    "\n",
    "# Как KNN работает?\n",
    "\n",
    "<img src=\"https://kevinzakka.github.io/assets/1nearestneigh.png\" width=\"400\" align=\"center\">\n",
    "<img src=\"https://kevinzakka.github.io/assets/20nearestneigh.png\" width=\"400\" align=\"center\">\n",
    "\n",
    "В случае классификации алгоритм K-ближайших соседей по существу сводится к подсчету большинства голосов между K наиболее похожими экземплярами для данного тестового экземпляра. Сходство экземпляров определяется по расстоянию между двумя точками данных. Популярным выбором является евклидово расстояние, но другие меры близости также могут быть подходящими для конкретной ситуации, включая расстояние Манхэттен, Чебышева и Хэмминга.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Знакомство с датасетом\n",
    "\n",
    "Сначала рассмотрим как работает уже готовый алгоритм из sklearn на примере датасета с разными видами стекла.\n",
    "\n",
    "Подробнее о датасете тут: [kaggle_dataset_link](https://www.kaggle.com/uciml/glass)\n",
    "\n",
    "Изучим вместе с KNN методы кросс-валидации, метрики и подбор параметров."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"./data/glass.csv\")\n",
    "print(\"Размерность данных: {}\\n\".format(data.shape))\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сколько есть видов стекла в нашем датасете?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.Type.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим на распределения признаков по разным классам;\n",
    "\n",
    "Рассмотрим для начала небольшую подвыборку признаков просто для удобства отрисовки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(data.iloc[:, [1,2,3,-1]], hue='Type')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видно, что не находится такой пары признаков, в координатах которых типы стекол легко бы разделялись. Также видно, что датасет неуравновешен и есть большой перекос в количестве примеров в сторону 1 и 2 классов. Однако в случае использования KNN для нас это не является большой проблемой. Почему?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Кросс-валидация (Скользящий контроль)\n",
    "\n",
    "**Терминология**\n",
    "<img src=\"http://www.vias.org/tmdatanaleng/img/hl_crossval.png\" width=\"400\" align=\"center\">\n",
    "\n",
    "**Оценкой скользящего контроля** называется средняя по всем разбиениям величина ошибки на контрольных подвыборках.\n",
    "\n",
    "Если выборка независима, то средняя ошибка скользящего контроля даёт несмещённую оценку вероятности ошибки.\n",
    "\n",
    "Выделяют следующие виды скользящего контроля\n",
    "\n",
    "* *Контроль на отложенных данных* (**hold-out CV**)\n",
    "    - Оценка производится по одному случайному разбиению \n",
    "* *Контроль по отдельным объектам* (**leave-one-out CV**)\n",
    "    - Поочередно из выборки убирается один объект, модель обучется на оставшейся выборке и делает предсказание на отложенном объекте.\n",
    "* *Контроль по $q$ блокам (**q-fold CV**)*\n",
    "    - Выборка случайным образом разбивается на $q$ непересекающихся блоков одинаковой (или почти одинаковой) длины.\n",
    "\n",
    "Подробнее про каждый из них и про доверительные интервалы для оценок результатов кросс-валидации можно почитать [здесь](http://www.machinelearning.ru/wiki/index.php?title=Скользящий_контроль).\n",
    "\n",
    "Еще один важный термин\n",
    "\n",
    "**Стратификация** заключается в том, чтобы заранее поделить выборку на части (страты), и при разбиении на обучение длины $m$ и контроль длины $k$ гарантировать, что каждая страта будет поделена между обучением и контролем в той же пропорции $m:k$.\n",
    "\n",
    "**Стратификация классов в задачах классификации** означает, что каждый класс (который и определяет страту) делится между обучением и контролем в пропорции $m:k$, где $m$ — размер обучающей выборки, а $k$ — размер тестовой выборки при данном варианте разбиения.\n",
    "Стратификация позволяет уменьшить разброс оценок скользящего контроля и сузить доверительные интервалы для них."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В sklearn есть встроенные средства для деления датасета на обучение и тест."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = data.iloc[:, :-1].values, data.Type.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold, KFold\n",
    "\n",
    "# стратификация согласно разметке по классам\n",
    "# деление датасета на обучение и тест один раз\n",
    "# это и есть hold-out CV\n",
    "# как правило при таком подходе k-fold cv производится отдельно над train частью датасета\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42, stratify=data.Type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# реализация q-fold cv со стратификацией по параметру y\n",
    "\n",
    "kfold_iterator = StratifiedKFold(n_splits=3, random_state=42)\n",
    "\n",
    "for train_index, test_index in kfold_iterator.split(X,y):\n",
    "    print(\"TRAIN:\", train_index[:5], \"TEST:\", test_index[:5])\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Другие виды кросс-валидации также доступны и с ними можно ознакомиться [здесь](http://scikit-learn.org/stable/modules/classes.html#module-sklearn.model_selection)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Исследуем KNN из коробки\n",
    "\n",
    "KNN имеет следующие важные параметры, которые напрямую затрагивают результаты предсказания\n",
    "    * weights\n",
    "    * n_neighbors\n",
    "    \n",
    "Прочитайте в документации про них подробнее."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# выбираем только нечетные значения k от 1 до 50\n",
    "neighbors = np.arange(1, 50, 2)\n",
    "\n",
    "# сюда мы сложим наши скоры\n",
    "cv_scores = []\n",
    "\n",
    "kf = StratifiedKFold(n_splits=7, random_state=42, shuffle=True)\n",
    "\n",
    "# выполним кросс-валидацию на 7 фолдах со стратификацией,\n",
    "# в качестве метрики возьмем простое accuracy\n",
    "for k in neighbors:\n",
    "    knn = KNeighborsClassifier(n_neighbors=k, weights='uniform')\n",
    "    scores = cross_val_score(knn, X, y, cv=kf, scoring='accuracy',)\n",
    "    cv_scores.append(scores.mean())\n",
    "    \n",
    "# отрисуем полученный результат\n",
    "plt.scatter(neighbors, cv_scores, label='best k={},\\n acc={}'.format(neighbors[np.argmax(cv_scores)],\n",
    "                                                               np.round(max(cv_scores),2)), )\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"K\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задания\n",
    "### Проведите эксперименты, чтобы ответить на следующие вопросы ~~и получше прочувствовать knn~~\n",
    "\n",
    "**Удобно код экспериментов писать в ячейках ниже задания с пометкой c номером задания**\n",
    "\n",
    "1. Для датасета со стеклом. Воспользуйтесь `StratifiedKFold` с количеством фолдов = 5. На каждом шаге кросс-валидации запоминайте precision & recall по каждому отдельному классу на текущей тестовой части выборки. В конце постройте графики отдельно для precision и отдельно для recall, где каждому классу будет сопоставлена усредненная по 5 фолдам метрика. \n",
    "\n",
    "    * Насколько сильно различаются предсказания knn для разных классов?\n",
    "\n",
    "    * Соответствует ли полученное распределение метрик по классам исходному распределению классов?\n",
    "\n",
    "    * Как изменится распределение метрик при изменении параметра k?\n",
    "\n",
    "2. Проведите эксперименты с одинаковым разбиением для cv, но различными значениями параметра `weights` у KNN.\n",
    "Постройте 2 графика в одних координатах: для значения среднего `f1_macro` на кросс-валидации для `uniform`, `distance` knn в зависимости от k. Сделайте вывод о влиянии параметра weights на предсказание модели для данной задачи.\n",
    "\n",
    "3. Постройте зависимость разброса предсказаний модели от k. В качестве cv возьмите StratifiedKFold c n_splits=7. Для этого удобно воспользоваться методом `kneighbors` у knn классификатора.\n",
    "Опишите свои наблюдения, сделайте выводы. \n",
    "\n",
    "4. Проведите эксперимент по уменьшению размерности векторов признаков в датасете#2. Для этой цели воспользуйтесь [PCA](http://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html). Постройте график зависимости accuracy от размерности входных данных. Эксперимент проводите при фиксированных параметрах KNN. Сделайте вывод.\n",
    "\n",
    "5.(optional) Воспользуйтесь датасетом, определенным в следующей ячейке (в дальнейшем датасет#2). Разбейте его на трейн и тест с `random_state`=42, `test_size`=0.3, `stratify` по y.\n",
    "Поэкспериментируйте с различными вариантами cv на трейн части и постарайтесь выбрать наилучшие параметры knn.\n",
    "После того, как параметры будут подобраны обучите модель на train и сделайте с ее помощью предсказание на test. Какое наилучшее значение accuracy у вас получилось на test части и при каких параметрах knn?\n",
    "\n",
    "    Задание считается успешно выполненным, если итоговый accuracy > 0.68\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Самостоятельная часть"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для задания **#1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score\n",
    "\n",
    "<your code>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для задания **#2**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neighbors = np.arange(1, 50, 2)\n",
    "\n",
    "<your code>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вероятно, что `distance` довольно полезная штука и стоит ее пользоваться, также можно придумать свои функции взвешивания и попытаться превзойти такое вот простое взвешивание."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для задания **#3**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42, stratify=data.Type)\n",
    "\n",
    "neighbors = np.arange(1, 100, 2)\n",
    "\n",
    "# сюда мы сложим наши скоры\n",
    "variances = []\n",
    "kf = StratifiedKFold(n_splits=7, random_state=42, shuffle=True)\n",
    "\n",
    "<your code>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для задания **#4**\n",
    "\n",
    "`проклятие размерности`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# датасет#2\n",
    "X,y = make_classification(n_samples=500, n_features=1000, n_informative=900, n_classes=2)\n",
    "scores = []\n",
    "knn = KNeighborsClassifier(n_neighbors=5, weights='uniform')\n",
    "\n",
    "<your code>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
